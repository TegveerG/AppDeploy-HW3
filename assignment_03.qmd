---
title: "Assignment 03"
subtitle: "Hyperparameter Tunning - Group Number 11"
date: 09/29/2023
date-modified: last-modified
date-format: long
format:
  html:
    theme: [cosmo, theme.scss]
    toc: true
    embed-resources: true
    number-sections: true
author:
  - name: Tegveer Ghura
    affiliations:
      - id: gu
        name: Georgetown University
        city: Washington
        state: DC
---


# Instructions (Remove the instructions before submission)

This assignment will deal with tuning the hyperparameters for the [online shopping dataset](https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset). Make sure to remove the instructions and only keep Q6 onward. The qmd file of this assignment is located in the [files folder](https://georgetown.instructure.com/files/11681026/download?download_frd=1).

- This is a group assignment with independent submission on Canvas. Collaboration is essential. Use Git for version control.
- Begin by setting your random seed as the last four digits of your GUID.
- Prefix each variable with 'g#groupnumber' (e.g., g01_variableName) to ensure uniqueness and to demonstrate originality in your group's work.
- add the names of all group members to the YAML header above.
- Use of Generative AI tools, including but not restricted to GPT-3 is strictly prohibited.

## Git Commit and Collaboration

- This is a group assignment. Collaboration is essential. Use Git for version control.
- Regular and meaningful commit messages are expected, indicating steady progress and contributions from all group members.
- Avoid large, infrequent commits. Instead, aim for more minor, frequent updates showing your code's evolution and thoughts.
- Collaboration tools, especially Git, should be used as a backup tool and a truly collaborative platform. Discuss, review, and merge each other's contributions.

# Grading Criteria

- The assignment is worth 75 points.
- There are three grading milestones in the assignment.
  - Adherence to Requirements, Coding Standards, Documentation, Runtime, and Efficiency (22 Points)
    - Adherence to Requirements (5 Points): Ensure all the given requirements of the assignment, including Git commits and collaboration, are met.
    - Coding Standards (5 Points): Code should be readable and maintainable. Ensure appropriate variable naming and code commenting.
    - Documentation (6 Points): Provide explanations or reasoning for using a particular command and describe the outputs. Avoid vague descriptions; aim for clarity and depth.
    - Runtime (3 Points): The code should execute without errors and handle possible exceptions.
    - Efficiency (3 Points): Implement efficient coding practices, avoid redundancy, and optimize for performance where applicable.
  - Collaborative Programming (13 Points)
    - GitHub Repository Structure (3 Points): A well-organized repository with clear directory structures and meaningful file names.
    - Number of Commits (3 Points): Reflects steady progress and contributions from all group members.
    - Commit Quality (3 Points): Clear, descriptive commit messages representing logical chunks of work. Avoid trivial commits like "typo fix."
    - Collaboration & Contribution (4 Points): Demonstrated teamwork where each member contributes significantly. This can be seen through pull requests, code reviews, and merge activities.
  - Assignment Questions (40 Points)

# Adherence to Requirements, Coding Standards, Documentation, Runtime, and Efficiency (22 Points)
This section is graded based on adherence to Requirements, Coding Standards,
Documentation, Runtime, and Efficiency.

# Collaborative Programming (13 Points)

This section is graded based on the Github submission. Each person needs to have made commits to the repository. GitHub Repository Structure, Number of Commits, Commit Quality, Collaboration, and Contribution are generally graded based on the group's overall performance. However, if there is a significant difference in the number of commits or contributions between group members, the instructor may adjust the grade accordingly.


# Assignment Questions (40 Points)

# Data Preparation (7 Points):

## Import the necessary libraries
```{python}
#| vscode: {languageId: python}
import random
random.seed(1310) # last 4 GUID digits
from seaborn.palettes import color_palette
from seaborn import set_palette
from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')
import plotly.io as pio
#pio.renderers.default = "notebook"
pio.renderers.default = "plotly_mimetype+notebook_connected"
```

## Load the dataset and display the dataframe (2 Points).

```{python}
#| vscode: {languageId: python}
filename = '../HW2/creditcard.csv'
CC = pd.read_csv(filename)

CC.head(6)
```

## Use `describe` to provide statistics on the pandas Dataframe (2 Points).

```{python}
# Add code here
CC.describe()
```

## Convert To Correct Dtypes and Clean DataFrame

```{python}
#| colab: {base_uri: 'https://localhost:8080/'}
#| outputId: 8f115a25-886d-43aa-fb1f-8fea814c0ed2
#| vscode: {languageId: python}
# Class is categorical variables but is encoded as integer
CC['Class'] = CC['Class'].astype('category')

# Drop NA's if any

CC.dropna(inplace=True)
```

## Split the dataset into a Training set and a Test set. Justify your preferred split (3 Points).

```{python}
#| vscode: {languageId: python}
from sklearn.model_selection import cross_val_score, RepeatedKFold, GridSearchCV, RandomizedSearchCV
from sklearn.ensemble import BaggingClassifier, RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(CC.iloc[:,0:-2],
                                        CC.iloc[:,-1],
                                        test_size=0.33,
                                        random_state=42)

# Reset and drop indexes after splitting, convert to numpy arrays and flatten
X_train.reset_index(inplace=True)
X_train = X_train.to_numpy()
y_train = y_train.reset_index().drop("index", axis=1).astype('category')
y_train = y_train.to_numpy().reshape(len(y_train),)

X_test.reset_index(inplace=True)
X_test = X_test.to_numpy()
y_test = y_test.reset_index().drop("index", axis=1).astype('category')
y_test = y_test.to_numpy().reshape(len(y_test),)
```

# Classification Routine (12 Points):

Execute a classification routine using RandomForestClassifier(), BaggingClassifier(), and XGboostclassifier(). Independently output the accuracy box plot as discussed in class. Use any package you are comfortable with (seaborn, matplotlib).

## RandomForestClassifier():

```{python}
#| vscode: {languageId: python}

RF = RandomForestClassifier()

cv = RepeatedKFold(n_splits=5, n_repeats=2, random_state=1)

RF_accuracy = cross_val_score(RF, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')

RF_weighted_f1 = cross_val_score(RF, X_train, y_train, scoring='f1_weighted', cv=cv, n_jobs=-1, error_score='raise')

mean_accuracy_percentage = RF_accuracy.mean() * 100
mean_weighted_f1_percentage = RF_weighted_f1.mean() * 100

print('Random Forest Mean Accuracy: %.3f Mean Weighted F1: %.3f' % (mean_accuracy_percentage, mean_weighted_f1_percentage))
```

```{python}
#| vscode: {languageId: python}

results = {}
results['Accuracy'] = RF_accuracy
results['Weighted_F1'] = RF_weighted_f1

RF_mod = pd.DataFrame(results)

# Melt the DataFrame to have 'Metric' as a new column indicating Accuracy or Weighted_F1
RF_mod_melted = pd.melt(RF_mod, value_vars=['Accuracy', 'Weighted_F1'], var_name='Metric', value_name='Value')

# Plotting using Seaborn
plt.figure(figsize=(8, 6))
sns.boxplot(x='Metric', y='Value', data=RF_mod_melted)
plt.xlabel('Metric')
plt.ylabel('Value')
plt.title('Accuracy vs Weighted_F1 Training Set')
plt.show()
plt.savefig('RF.jpeg')
```

```{python}
#| vscode: {languageId: python}

import pickle

RF.fit(X_train, y_train)

# Save to file in the current working directory
pkl_filename = "RF.pkl"
with open(pkl_filename, 'wb') as file:
  pickle.dump(RF, file)

# Load from file
with open(pkl_filename, 'rb') as file:
  pickle_model = pickle.load(file)
  score = pickle_model.score(X_test, y_test)
  print("Test Set Accuracy: {0:.2f} %".format(100 * score))
  Y_predict = pickle_model.predict(X_test)
```

```{python}
#| vscode: {languageId: python}

conf_matrix = confusion_matrix(y_test, Y_predict)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['Not Fraud','Fraud'], )

# save the plot

disp.plot(cmap='YlGnBu',values_format='d',ax=None)
plt.title('Confusion Matrix for Random Forest', fontsize=15, color='#336699',loc='center')
plt.savefig('confusion_matrix_RF.png')
```

## BaggingClassifier():

```{python}
Bagging = BaggingClassifier()

cv = RepeatedKFold(n_splits=5, n_repeats=2, random_state=1)

Bagging_accuracy = cross_val_score(Bagging, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')

Bagging_weighted_f1 = cross_val_score(Bagging, X_train, y_train, scoring='f1_weighted', cv=cv, n_jobs=-1, error_score='raise')

mean_accuracy_percentage = Bagging_accuracy.mean() * 100
mean_weighted_f1_percentage = Bagging_weighted_f1.mean() * 100

print('Bagging Mean Accuracy: %.3f Mean Weighted F1: %.3f' % (mean_accuracy_percentage, mean_weighted_f1_percentage))
```

```{python}
#| vscode: {languageId: python}

results = {}
results['Accuracy'] = Bagging_accuracy
results['Weighted_F1'] = Bagging_weighted_f1

Bagging_mod = pd.DataFrame(results)

# Melt the DataFrame to have 'Metric' as a new column indicating Accuracy or Weighted_F1
Bagging_mod_melted = pd.melt(Bagging_mod, value_vars=['Accuracy', 'Weighted_F1'], var_name='Metric', value_name='Value')

# Plotting using Seaborn
plt.figure(figsize=(8, 6))
sns.boxplot(x='Metric', y='Value', data=Bagging_mod_melted)
plt.xlabel('Metric')
plt.ylabel('Value')
plt.title('Accuracy vs Weighted_F1 Training Set')
plt.show()
plt.savefig('Bagging.jpeg')
```

```{python}
#| vscode: {languageId: python}

import pickle

Bagging.fit(X_train, y_train)

# Save to file in the current working directory
pkl_filename = "Bagging.pkl"
with open(pkl_filename, 'wb') as file:
  pickle.dump(Bagging, file)

# Load from file
with open(pkl_filename, 'rb') as file:
  pickle_model = pickle.load(file)
  score = pickle_model.score(X_test, y_test)
  print("Test Set Accuracy: {0:.2f} %".format(100 * score))
  Y_predict = pickle_model.predict(X_test)
```

## XGboostclassifier():

```{python}

```

# Classification with GridSearchCV (8 Points):

## RandomForestClassifier():

Replicate the classification from Q2 using GridsearchCV().
```{python}
# Add code here

```



# Classification with RandomSearchCV (8 Points):

Replicate the classification from Q2 using RandomSearchCV().

```{python}
# Add code here

```

# Comparison and Analysis (5 Points):

Compare the results from Q2, Q3, and Q4. Describe the best hyperparameters for all three experiments.